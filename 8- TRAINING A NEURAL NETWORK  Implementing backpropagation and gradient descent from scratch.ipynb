{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMDVaz4FK2iK4oaVBa1TN/e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":30,"metadata":{"id":"Y_CWhEH1WF3i","executionInfo":{"status":"ok","timestamp":1726529211218,"user_tz":180,"elapsed":354,"user":{"displayName":"NEHEMIAS NICOLÁS RIVERA","userId":"15262051941950258843"}}},"outputs":[],"source":["import numpy as np\n","from random import random"]},{"cell_type":"code","source":["# save activations and derivatives\n","# implement backpropagation\n","# implement gradient decent\n","# implement train\n","# train our net woth some dummy dataset\n","# make some prediction\n","\n","class MLP:\n","\n","  def __init__(self, num_inputs=3, num_hidden=[3, 3], num_outputs=2):\n","    \"\"\"\n","    MLP constructor\n","    Args:\n","      num_inputs (int): numero de entradas\n","      num_hidden (list): numero de neuronas ocultas\n","      num_outputs (int): numero de salidas\n","    \"\"\"\n","    self.num_inputs = num_inputs\n","    self.num_hidden = num_hidden\n","    self.num_outputs = num_outputs\n","\n","    # crear representacion generica de las capas\n","    layers = [num_inputs] + num_hidden + [num_outputs]\n","\n","    weights = []\n","    for i in range(len(layers) - 1):\n","      w = np.random.rand(layers[i], layers[i + 1])\n","      weights.append(w)\n","    self.weights = weights\n","\n","    derivatives = []\n","    for i in range(len(layers)-1):  #Si tenemos tres capas tenemos dos matrices W\n","      a = np.zeros((layers[i], layers[i+1]))\n","      derivatives.append(a)\n","    self.derivatives = derivatives\n","\n","    # crear representacion de las activaciones de las capas\n","    activations = []\n","    for i in range(len(layers)):\n","      a = np.zeros(layers[i])\n","      activations.append(a)\n","    self.activations = activations\n","\n","  def forward_propagate(self, inputs):\n","    \"\"\"\n","    Calcula la propagacion forward a traves de la red basado en las entradas\n","    Args:\n","      inputs (ndarray): entradas a la red\n","    Returns:\n","      activations (ndarray): salidas de la red\n","    \"\"\"\n","    activations = inputs\n","\n","    # la activacion de la primera capa\n","    self.activations[0] = activations\n","\n","    # itera a traves de las capa de la red\n","    for i, w in enumerate(self.weights):\n","      # Calcula las entradas netas\n","      net_inputs = np.dot(activations, w)\n","\n","      # Calcula la activacion\n","      activations = self._sigmoid(net_inputs)\n","      self.activations[i+1]= activations #guardamos la activacion\n","\n","    # a_3 = s(h_3)\n","    # h_3 = a_2 * W_2 ---> i = 2\n","\n","    return activations\n","\n","  def back_propagate(self,error, verbose=False):\n","    \"\"\"Backpropogates an error signal.\n","    Args:\n","        error (ndarray): The error to backprop.\n","    Returns:\n","        error (ndarray): The final error of the input\n","    \"\"\"\n","\n","    #Este metodo de backpropagation funciona para infita cantidad de capas\n","\n","    # dE/dW_i = (y - a_[i+1]) * s'(h_[i+1]) * a_i ---> error * s' * ai\n","    # s'(h_[i+1]) = s(h_[i+1]) * (1 - s(h_[i+1]))\n","    # s(h_[i+1]) = a_[i+1]\n","\n","    # dE/dw_[i-1] = (y - a_[i+1]) * s'(h_[i+1]) * W_i * s'(h_i) * a_[i-1]\n","\n","    # recorremos desde la ultima capa hasta la primera (al reves)\n","    for i in reversed(range(len(self.derivatives))):\n","      activations  = self.activations [i+1]\n","\n","      delta = error * self._sigmoid_derivative(activations ) #ndarray([0.1, 0.2]) --> ndarray([[0.1, 0.2]])\n","      delta_reshaped = delta.reshape(delta.shape[0], -1).T\n","\n","      current_activations = self.activations[i] #ndarray([0.1, 0.2]) --> ndarray([0.1], [0.2])\n","      current_activations_reshape = current_activations.reshape(current_activations.shape[0],-1)\n","\n","      self.derivatives[i] = np.dot(current_activations_reshape, delta_reshaped)\n","\n","      error = np.dot(delta, self.weights[i].T)  #calcular el error de la capa anterior ((y - a_[i+1]) * s'(h_[i+1]) * W_i)\n","\n","      if verbose:\n","        print(\"Derivatives for W{}: {}\".format(i,self.derivatives[i]))\n","\n","    return error\n","\n","  def train(self, inputs, targets, epochs, learning_rate):\n","\n","    for i in range(epochs):\n","      sum_error = 0\n","      for (input,target) in zip(inputs,targets):\n","        # forward propagation\n","        output = self.forward_propagate(input)\n","        # calcula error\n","        error = target - output\n","        # backpropagation\n","        self.back_propagate(error)\n","        # actualiza pesos (gradiente decendiente)\n","        self.gradient_descent(learning_rate)\n","        #report error para esta epoca (se acumula)\n","        sum_error += self._mse(target, output)\n","\n","      print(\"Error: {} at epoch {}\".format(sum_error/len(inputs), i))\n","\n","  def gradient_descent(self, learning_rate):\n","    for i in range(len(self.weights)):\n","      weights = self.weights[i]\n","      derivatives = self.derivatives[i]\n","      weights += derivatives * learning_rate\n","\n","  def _sigmoid_derivative(self,x):\n","    \"\"\"\n","    Calcula la derivada de la funcion sigmoid\n","    Args:\n","      x (float): value to be processed\n","    Returns:\n","      y (float): output\n","    \"\"\"\n","    return x * (1.0 - x)\n","\n","  def _mse(self, target, output):\n","    \"\"\"\n","    Calcula el error cuadratico medio\n","    Args:\n","      target (ndarray): el target de la red\n","      output (ndarray): la salida de la red\n","    Returns:\n","      error\n","    \"\"\"\n","    return np.average((target - output) ** 2)\n","\n","  def _sigmoid(self, x):\n","    \"\"\"\n","    Sigmoid activation function\n","    Args:\n","      x (float): value to be processed\n","    Returns:\n","      y (float): output\n","    \"\"\"\n","    return 1 / (1 + np.exp(-x))\n","\n",""],"metadata":{"id":"0vgVoQQ-WKmG","executionInfo":{"status":"ok","timestamp":1726529211219,"user_tz":180,"elapsed":3,"user":{"displayName":"NEHEMIAS NICOLÁS RIVERA","userId":"15262051941950258843"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","  # create a dataset to train a network for the sum operation\n","  inputs = np.array([[random()/2 for _ in range(2)] for _ in range(1000)]) # array([[0.1, 0.2], [0.3,0.4]])\n","  targets = np.array([[i[0] + i[1]] for i in inputs]) # array([[0.3], [0.7]])\n","\n","  # crear un MLP\n","  mlp = MLP(2,[5],1)\n","\n","  # entrenar el MLP\n","  mlp.train(inputs, targets, 150, 0.1)\n","\n","    # crear data dummy\n","  input = np.array([0.3, 0.1])\n","  target = np.array([0.4])\n","\n","  # hacer una prediccion\n","  output = mlp.forward_propagate(input)\n","  print()\n","  print()\n","  print(\"Our network believes that {} + {} is equal to {}\".format(input[0], input[1], output[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YckebmtWLRZ","executionInfo":{"status":"ok","timestamp":1726529610996,"user_tz":180,"elapsed":9057,"user":{"displayName":"NEHEMIAS NICOLÁS RIVERA","userId":"15262051941950258843"}},"outputId":"b4346e9a-c382-4261-8e68-8da224b938ca"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: 0.04863223396444173 at epoch 0\n","Error: 0.04342168084833459 at epoch 1\n","Error: 0.04293793488705722 at epoch 2\n","Error: 0.04232214833191854 at epoch 3\n","Error: 0.04152217308588721 at epoch 4\n","Error: 0.04047803815828766 at epoch 5\n","Error: 0.039124162177527004 at epoch 6\n","Error: 0.03739564096923335 at epoch 7\n","Error: 0.035240361899328415 at epoch 8\n","Error: 0.032637193455507904 at epoch 9\n","Error: 0.029616741458744045 at epoch 10\n","Error: 0.02627563388232458 at epoch 11\n","Error: 0.022772376170959358 at epoch 12\n","Error: 0.019298942146415938 at epoch 13\n","Error: 0.01603716630603756 at epoch 14\n","Error: 0.013120396494220346 at epoch 15\n","Error: 0.010616776862757096 at epoch 16\n","Error: 0.008535387755638073 at epoch 17\n","Error: 0.006844942907921382 at epoch 18\n","Error: 0.005493698610431743 at epoch 19\n","Error: 0.004424363852896708 at epoch 20\n","Error: 0.003582855120578137 at epoch 21\n","Error: 0.00292225583746748 at epoch 22\n","Error: 0.002403826032237494 at epoch 23\n","Error: 0.0019965109626671586 at epoch 24\n","Error: 0.0016758506856060543 at epoch 25\n","Error: 0.0014227701172232837 at epoch 26\n","Error: 0.001222467272621845 at epoch 27\n","Error: 0.0010634757813115512 at epoch 28\n","Error: 0.0009369097748448067 at epoch 29\n","Error: 0.0008358712244790166 at epoch 30\n","Error: 0.0007549915465827942 at epoch 31\n","Error: 0.0006900798187793925 at epoch 32\n","Error: 0.0006378537534468163 at epoch 33\n","Error: 0.0005957341030908515 at epoch 34\n","Error: 0.0005616873648844893 at epoch 35\n","Error: 0.0005341051611726069 at epoch 36\n","Error: 0.0005117114637006938 at epoch 37\n","Error: 0.0004934909866092188 at epoch 38\n","Error: 0.00047863371390489295 at epoch 39\n","Error: 0.0004664917637593169 at epoch 40\n","Error: 0.0004565457199958677 at epoch 41\n","Error: 0.00044837825654080394 at epoch 42\n","Error: 0.00044165340202659205 at epoch 43\n","Error: 0.00043610018342845475 at epoch 44\n","Error: 0.0004314996826878484 at epoch 45\n","Error: 0.0004276747633193425 at epoch 46\n","Error: 0.00042448189323077346 at epoch 47\n","Error: 0.0004218046189054893 at epoch 48\n","Error: 0.00041954834470675316 at epoch 49\n","Error: 0.0004176361468042418 at epoch 50\n","Error: 0.0004160054096332064 at epoch 51\n","Error: 0.0004146051180238398 at epoch 52\n","Error: 0.00041339367329341887 at epoch 53\n","Error: 0.0004123371290223785 at epoch 54\n","Error: 0.00041140776371295824 at epoch 55\n","Error: 0.0004105829244043299 at epoch 56\n","Error: 0.0004098440886207658 at epoch 57\n","Error: 0.00040917610254820715 at epoch 58\n","Error: 0.0004085665616765648 at epoch 59\n","Error: 0.0004080053067787115 at epoch 60\n","Error: 0.0004074840133862152 at epoch 61\n","Error: 0.0004069958571487483 at epoch 62\n","Error: 0.0004065352408501111 at epoch 63\n","Error: 0.00040609757157162007 at epoch 64\n","Error: 0.0004056790786795883 at epoch 65\n","Error: 0.0004052766650748078 at epoch 66\n","Error: 0.000404887785563495 at epoch 67\n","Error: 0.00040451034735811185 at epoch 68\n","Error: 0.0004041426286466438 at epoch 69\n","Error: 0.0004037832119227658 at epoch 70\n","Error: 0.00040343092938115925 at epoch 71\n","Error: 0.00040308481817925943 at epoch 72\n","Error: 0.0004027440837709366 at epoch 73\n","Error: 0.0004024080698466057 at epoch 74\n","Error: 0.00040207623368232963 at epoch 75\n","Error: 0.0004017481259189844 at epoch 76\n","Error: 0.0004014233739708523 at epoch 77\n","Error: 0.00040110166840856646 at epoch 78\n","Error: 0.0004007827517802025 at epoch 79\n","Error: 0.0004004664094315072 at epoch 80\n","Error: 0.0004001524619656575 at epoch 81\n","Error: 0.00039984075904797535 at epoch 82\n","Error: 0.00039953117431418137 at epoch 83\n","Error: 0.00039922360118428213 at epoch 84\n","Error: 0.0003989179494198924 at epoch 85\n","Error: 0.0003986141422919044 at epoch 86\n","Error: 0.00039831211424943706 at epoch 87\n","Error: 0.00039801180900051126 at epoch 88\n","Error: 0.00039771317793101606 at epoch 89\n","Error: 0.0003974161788017064 at epoch 90\n","Error: 0.00039712077467373905 at epoch 91\n","Error: 0.00039682693302213847 at epoch 92\n","Error: 0.00039653462500386483 at epoch 93\n","Error: 0.00039624382485306834 at epoch 94\n","Error: 0.0003959545093810503 at epoch 95\n","Error: 0.00039566665756245954 at epoch 96\n","Error: 0.00039538025019250975 at epoch 97\n","Error: 0.00039509526960276344 at epoch 98\n","Error: 0.00039481169942519106 at epoch 99\n","Error: 0.00039452952439609156 at epoch 100\n","Error: 0.0003942487301929054 at epoch 101\n","Error: 0.0003939693032982277 at epoch 102\n","Error: 0.0003936912308862875 at epoch 103\n","Error: 0.0003934145007280581 at epoch 104\n","Error: 0.0003931391011117623 at epoch 105\n","Error: 0.0003928650207761784 at epoch 106\n","Error: 0.0003925922488545452 at epoch 107\n","Error: 0.0003923207748272941 at epoch 108\n","Error: 0.0003920505884821207 at epoch 109\n","Error: 0.0003917816798801737 at epoch 110\n","Error: 0.0003915140393273412 at epoch 111\n","Error: 0.00039124765734981526 at epoch 112\n","Error: 0.0003909825246732221 at epoch 113\n","Error: 0.0003907186322047496 at epoch 114\n","Error: 0.00039045597101779937 at epoch 115\n","Error: 0.00039019453233874905 at epoch 116\n","Error: 0.00038993430753551456 at epoch 117\n","Error: 0.00038967528810761825 at epoch 118\n","Error: 0.0003894174656775519 at epoch 119\n","Error: 0.00038916083198321154 at epoch 120\n","Error: 0.000388905378871281 at epoch 121\n","Error: 0.0003886510982913964 at epoch 122\n","Error: 0.0003883979822909943 at epoch 123\n","Error: 0.00038814602301074226 at epoch 124\n","Error: 0.0003878952126804702 at epoch 125\n","Error: 0.0003876455436155414 at epoch 126\n","Error: 0.0003873970082135923 at epoch 127\n","Error: 0.00038714959895159523 at epoch 128\n","Error: 0.0003869033083832203 at epoch 129\n","Error: 0.0003866581291364279 at epoch 130\n","Error: 0.00038641405391128393 at epoch 131\n","Error: 0.000386171075477965 at epoch 132\n","Error: 0.00038592918667493926 at epoch 133\n","Error: 0.0003856883804072804 at epoch 134\n","Error: 0.0003854486496451154 at epoch 135\n","Error: 0.00038520998742220413 at epoch 136\n","Error: 0.0003849723868345941 at epoch 137\n","Error: 0.00038473584103939496 at epoch 138\n","Error: 0.0003845003432536132 at epoch 139\n","Error: 0.00038426588675307034 at epoch 140\n","Error: 0.00038403246487138544 at epoch 141\n","Error: 0.00038380007099901874 at epoch 142\n","Error: 0.0003835686985823574 at epoch 143\n","Error: 0.00038333834112286335 at epoch 144\n","Error: 0.00038310899217625766 at epoch 145\n","Error: 0.00038288064535173954 at epoch 146\n","Error: 0.00038265329431125185 at epoch 147\n","Error: 0.00038242693276876707 at epoch 148\n","Error: 0.00038220155448961024 at epoch 149\n","\n","\n","Our network believes that 0.3 + 0.1 is equal to 0.3931735821927642\n"]}]}]}