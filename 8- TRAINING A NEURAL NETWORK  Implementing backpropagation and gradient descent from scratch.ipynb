{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":354,"status":"ok","timestamp":1726529211218,"user":{"displayName":"NEHEMIAS NICOLÁS RIVERA","userId":"15262051941950258843"},"user_tz":180},"id":"Y_CWhEH1WF3i"},"outputs":[],"source":["import numpy as np\n","from random import random"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1726529211219,"user":{"displayName":"NEHEMIAS NICOLÁS RIVERA","userId":"15262051941950258843"},"user_tz":180},"id":"0vgVoQQ-WKmG"},"outputs":[],"source":["# save activations and derivatives\n","# implement backpropagation\n","# implement gradient decent\n","# implement train\n","# train our net woth some dummy dataset\n","# make some prediction\n","\n","class MLP:\n","\n","  def __init__(self, num_inputs=3, num_hidden=[3, 3], num_outputs=2):\n","    \"\"\"\n","    MLP constructor\n","    Args:\n","      num_inputs (int): numero de entradas\n","      num_hidden (list): numero de neuronas ocultas\n","      num_outputs (int): numero de salidas\n","    \"\"\"\n","    self.num_inputs = num_inputs\n","    self.num_hidden = num_hidden\n","    self.num_outputs = num_outputs\n","\n","    # crear representacion generica de las capas\n","    layers = [num_inputs] + num_hidden + [num_outputs]\n","\n","    weights = []\n","    for i in range(len(layers) - 1):\n","      w = np.random.rand(layers[i], layers[i + 1])\n","      weights.append(w)\n","    self.weights = weights\n","\n","    derivatives = []\n","    for i in range(len(layers)-1):  #Si tenemos tres capas tenemos dos matrices W\n","      a = np.zeros((layers[i], layers[i+1]))\n","      derivatives.append(a)\n","    self.derivatives = derivatives\n","\n","    # crear representacion de las activaciones de las capas\n","    activations = []\n","    for i in range(len(layers)):\n","      a = np.zeros(layers[i])\n","      activations.append(a)\n","    self.activations = activations\n","\n","  def forward_propagate(self, inputs):\n","    \"\"\"\n","    Calcula la propagacion forward a traves de la red basado en las entradas\n","    Args:\n","      inputs (ndarray): entradas a la red\n","    Returns:\n","      activations (ndarray): salidas de la red\n","    \"\"\"\n","    activations = inputs\n","\n","    # la activacion de la primera capa\n","    self.activations[0] = activations\n","\n","    # itera a traves de las capa de la red\n","    for i, w in enumerate(self.weights):\n","      # Calcula las entradas netas\n","      net_inputs = np.dot(activations, w)\n","\n","      # Calcula la activacion\n","      activations = self._sigmoid(net_inputs)\n","      self.activations[i+1]= activations #guardamos la activacion\n","\n","    # a_3 = s(h_3)\n","    # h_3 = a_2 * W_2 ---> i = 2\n","\n","    return activations\n","\n","  def back_propagate(self,error, verbose=False):\n","    \"\"\"Backpropogates an error signal.\n","    Args:\n","        error (ndarray): The error to backprop.\n","    Returns:\n","        error (ndarray): The final error of the input\n","    \"\"\"\n","\n","    #Este metodo de backpropagation funciona para infita cantidad de capas\n","\n","    # dE/dW_i = (y - a_[i+1]) * s'(h_[i+1]) * a_i ---> error * s' * ai\n","    # s'(h_[i+1]) = s(h_[i+1]) * (1 - s(h_[i+1]))\n","    # s(h_[i+1]) = a_[i+1]\n","\n","    # dE/dw_[i-1] = (y - a_[i+1]) * s'(h_[i+1]) * W_i * s'(h_i) * a_[i-1]\n","\n","    # recorremos desde la ultima capa hasta la primera (al reves)\n","    for i in reversed(range(len(self.derivatives))):\n","      activations  = self.activations [i+1]\n","\n","      delta = error * self._sigmoid_derivative(activations ) #ndarray([0.1, 0.2]) --> ndarray([[0.1, 0.2]])\n","      delta_reshaped = delta.reshape(delta.shape[0], -1).T\n","\n","      current_activations = self.activations[i] #ndarray([0.1, 0.2]) --> ndarray([0.1], [0.2])\n","      current_activations_reshape = current_activations.reshape(current_activations.shape[0],-1)\n","\n","      self.derivatives[i] = np.dot(current_activations_reshape, delta_reshaped)\n","\n","      error = np.dot(delta, self.weights[i].T)  #calcular el error de la capa anterior ((y - a_[i+1]) * s'(h_[i+1]) * W_i)\n","\n","      if verbose:\n","        print(\"Derivatives for W{}: {}\".format(i,self.derivatives[i]))\n","\n","    return error\n","\n","  def train(self, inputs, targets, epochs, learning_rate):\n","\n","    for i in range(epochs):\n","      sum_error = 0\n","      for (input,target) in zip(inputs,targets):\n","        # forward propagation\n","        output = self.forward_propagate(input)\n","        # calcula error\n","        error = target - output\n","        # backpropagation\n","        self.back_propagate(error)\n","        # actualiza pesos (gradiente decendiente)\n","        self.gradient_descent(learning_rate)\n","        #report error para esta epoca (se acumula)\n","        sum_error += self._mse(target, output)\n","\n","      print(\"Error: {} at epoch {}\".format(sum_error/len(inputs), i))\n","\n","  def gradient_descent(self, learning_rate):\n","    for i in range(len(self.weights)):\n","      weights = self.weights[i]\n","      derivatives = self.derivatives[i]\n","      weights += derivatives * learning_rate\n","\n","  def _sigmoid_derivative(self,x):\n","    \"\"\"\n","    Calcula la derivada de la funcion sigmoid\n","    Args:\n","      x (float): value to be processed\n","    Returns:\n","      y (float): output\n","    \"\"\"\n","    return x * (1.0 - x)\n","\n","  def _mse(self, target, output):\n","    \"\"\"\n","    Calcula el error cuadratico medio\n","    Args:\n","      target (ndarray): el target de la red\n","      output (ndarray): la salida de la red\n","    Returns:\n","      error\n","    \"\"\"\n","    return np.average((target - output) ** 2)\n","\n","  def _sigmoid(self, x):\n","    \"\"\"\n","    Sigmoid activation function\n","    Args:\n","      x (float): value to be processed\n","    Returns:\n","      y (float): output\n","    \"\"\"\n","    return 1 / (1 + np.exp(-x))\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9057,"status":"ok","timestamp":1726529610996,"user":{"displayName":"NEHEMIAS NICOLÁS RIVERA","userId":"15262051941950258843"},"user_tz":180},"id":"5YckebmtWLRZ","outputId":"b4346e9a-c382-4261-8e68-8da224b938ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error: 0.05503434988084922 at epoch 0\n","Error: 0.041564530748654925 at epoch 1\n","Error: 0.041142508187204614 at epoch 2\n","Error: 0.040606555107802506 at epoch 3\n","Error: 0.03991235879786054 at epoch 4\n","Error: 0.0390089417944121 at epoch 5\n","Error: 0.03783983639163752 at epoch 6\n","Error: 0.036347550823879256 at epoch 7\n","Error: 0.03448249509201753 at epoch 8\n","Error: 0.0322169472774323 at epoch 9\n","Error: 0.029562243002588678 at epoch 10\n","Error: 0.02658329197736269 at epoch 11\n","Error: 0.02340109873284828 at epoch 12\n","Error: 0.02017600619170589 at epoch 13\n","Error: 0.017074325718748947 at epoch 14\n","Error: 0.014232525472703192 at epoch 15\n","Error: 0.011735072414687462 at epoch 16\n","Error: 0.009612181961534402 at epoch 17\n","Error: 0.007852057967405556 at epoch 18\n","Error: 0.006417859938061096 at epoch 19\n","Error: 0.005262309367301531 at epoch 20\n","Error: 0.004337362130908138 at epoch 21\n","Error: 0.0035993397691128806 at epoch 22\n","Error: 0.0030109373899737243 at epoch 23\n","Error: 0.0025414540416231935 at epoch 24\n","Error: 0.0021661793065623695 at epoch 25\n","Error: 0.0018654808612371609 at epoch 26\n","Error: 0.001623870090851379 at epoch 27\n","Error: 0.0014291657838825923 at epoch 28\n","Error: 0.0012717935625341857 at epoch 29\n","Error: 0.001144220023846811 at epoch 30\n","Error: 0.0010405051160839419 at epoch 31\n","Error: 0.0009559521882707819 at epoch 32\n","Error: 0.000886836080388082 at epoch 33\n","Error: 0.0008301923916535822 at epoch 34\n","Error: 0.0007836541965113988 at epoch 35\n","Error: 0.0007453253554796696 at epoch 36\n","Error: 0.0007136819874900603 at epoch 37\n","Error: 0.0006874956130801632 at epoch 38\n","Error: 0.0006657729976275925 at epoch 39\n","Error: 0.0006477088950186688 at epoch 40\n","Error: 0.0006326487870482899 at epoch 41\n","Error: 0.0006200593946683763 at epoch 42\n","Error: 0.0006095052543257781 at epoch 43\n","Error: 0.0006006300455153199 at epoch 44\n","Error: 0.0005931416546234563 at epoch 45\n","Error: 0.0005868001881584591 at epoch 46\n","Error: 0.0005814083229054313 at epoch 47\n","Error: 0.0005768035144532546 at epoch 48\n","Error: 0.0005728516887117265 at epoch 49\n","Error: 0.0005694421208306416 at epoch 50\n","Error: 0.0005664832678871391 at epoch 51\n","Error: 0.0005638993700001411 at epoch 52\n","Error: 0.0005616276723214797 at epoch 53\n","Error: 0.0005596161500393951 at epoch 54\n","Error: 0.0005578216419380057 at epoch 55\n","Error: 0.0005562083165810748 at epoch 56\n","Error: 0.0005547464099008971 at epoch 57\n","Error: 0.0005534111846977376 at epoch 58\n","Error: 0.0005521820719294722 at epoch 59\n","Error: 0.0005510419611896401 at epoch 60\n","Error: 0.0005499766138203729 at epoch 61\n","Error: 0.0005489741769859673 at epoch 62\n","Error: 0.0005480247809798727 at epoch 63\n","Error: 0.0005471202052387363 at epoch 64\n","Error: 0.0005462536011391714 at epoch 65\n","Error: 0.0005454192617731005 at epoch 66\n","Error: 0.0005446124306284515 at epoch 67\n","Error: 0.0005438291425182317 at epoch 68\n","Error: 0.0005430660912617396 at epoch 69\n","Error: 0.000542320519574691 at epoch 70\n","Error: 0.0005415901274087767 at epoch 71\n","Error: 0.0005408729956266716 at epoch 72\n","Error: 0.0005401675224308103 at epoch 73\n","Error: 0.0005394723704038853 at epoch 74\n","Error: 0.0005387864223824077 at epoch 75\n","Error: 0.0005381087446854787 at epoch 76\n","Error: 0.0005374385564700808 at epoch 77\n","Error: 0.0005367752041908475 at epoch 78\n","Error: 0.0005361181403136623 at epoch 79\n","Error: 0.0005354669055749187 at epoch 80\n","Error: 0.0005348211141965566 at epoch 81\n","Error: 0.0005341804415654145 at epoch 82\n","Error: 0.0005335446139672855 at epoch 83\n","Error: 0.0005329134000342741 at epoch 84\n","Error: 0.0005322866036207261 at epoch 85\n","Error: 0.0005316640578703472 at epoch 86\n","Error: 0.0005310456202765064 at epoch 87\n","Error: 0.0005304311685705737 at epoch 88\n","Error: 0.000529820597300515 at epoch 89\n","Error: 0.0005292138149848337 at epoch 90\n","Error: 0.0005286107417459916 at epoch 91\n","Error: 0.0005280113073433293 at epoch 92\n","Error: 0.0005274154495387941 at epoch 93\n","Error: 0.0005268231127398314 at epoch 94\n","Error: 0.0005262342468730306 at epoch 95\n","Error: 0.0005256488064498423 at epoch 96\n","Error: 0.0005250667497921 at epoch 97\n","Error: 0.0005244880383904626 at epoch 98\n","Error: 0.0005239126363733344 at epoch 99\n","Error: 0.0005233405100676241 at epoch 100\n","Error: 0.000522771627635751 at epoch 101\n","Error: 0.0005222059587759541 at epoch 102\n","Error: 0.0005216434744751193 at epoch 103\n","Error: 0.000521084146805139 at epoch 104\n","Error: 0.0005205279487553195 at epoch 105\n","Error: 0.0005199748540946706 at epoch 106\n","Error: 0.0005194248372588472 at epoch 107\n","Error: 0.0005188778732575152 at epoch 108\n","Error: 0.0005183339375985277 at epoch 109\n","Error: 0.0005177930062260034 at epoch 110\n","Error: 0.0005172550554698001 at epoch 111\n","Error: 0.0005167200620044076 at epoch 112\n","Error: 0.0005161880028155278 at epoch 113\n","Error: 0.000515658855172986 at epoch 114\n","Error: 0.0005151325966088016 at epoch 115\n","Error: 0.0005146092048994649 at epoch 116\n","Error: 0.0005140886580516618 at epoch 117\n","Error: 0.0005135709342907596 at epoch 118\n","Error: 0.0005130560120515673 at epoch 119\n","Error: 0.0005125438699708844 at epoch 120\n","Error: 0.0005120344868815372 at epoch 121\n","Error: 0.000511527841807554 at epoch 122\n","Error: 0.0005110239139602698 at epoch 123\n","Error: 0.0005105226827351701 at epoch 124\n","Error: 0.0005100241277092936 at epoch 125\n","Error: 0.0005095282286390823 at epoch 126\n","Error: 0.0005090349654585743 at epoch 127\n","Error: 0.0005085443182778333 at epoch 128\n","Error: 0.0005080562673815951 at epoch 129\n","Error: 0.0005075707932280249 at epoch 130\n","Error: 0.0005070878764475811 at epoch 131\n","Error: 0.0005066074978419354 at epoch 132\n","Error: 0.0005061296383829332 at epoch 133\n","Error: 0.0005056542792115614 at epoch 134\n","Error: 0.0005051814016369339 at epoch 135\n","Error: 0.0005047109871352477 at epoch 136\n","Error: 0.0005042430173487359 at epoch 137\n","Error: 0.0005037774740845977 at epoch 138\n","Error: 0.0005033143393138969 at epoch 139\n","Error: 0.0005028535951704416 at epoch 140\n","Error: 0.0005023952239496246 at epoch 141\n","Error: 0.0005019392081072524 at epoch 142\n","Error: 0.0005014855302583285 at epoch 143\n","Error: 0.0005010341731758355 at epoch 144\n","Error: 0.0005005851197894611 at epoch 145\n","Error: 0.0005001383531843401 at epoch 146\n","Error: 0.0004996938565997458 at epoch 147\n","Error: 0.0004992516134277839 at epoch 148\n","Error: 0.0004988116072120579 at epoch 149\n","\n","\n","Our network believes that 0.3 + 0.1 is equal to 0.39401058773435105\n"]}],"source":["if __name__ == \"__main__\":\n","\n","  # create a dataset to train a network for the sum operation\n","  inputs = np.array([[random()/2 for _ in range(2)] for _ in range(1000)]) # array([[0.1, 0.2], [0.3,0.4]])\n","  targets = np.array([[i[0] + i[1]] for i in inputs]) # array([[0.3], [0.7]])\n","\n","  # crear un MLP\n","  mlp = MLP(2,[5],1)\n","\n","  # entrenar el MLP\n","  mlp.train(inputs, targets, 150, 0.1)\n","\n","    # crear data dummy\n","  input = np.array([0.3, 0.1])\n","  target = np.array([0.4])\n","\n","  # hacer una prediccion\n","  output = mlp.forward_propagate(input)\n","  print()\n","  print()\n","  print(\"Our network believes that {} + {} is equal to {}\".format(input[0], input[1], output[0]))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMDVaz4FK2iK4oaVBa1TN/e","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":0}
