{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":354,"status":"ok","timestamp":1726529211218,"user":{"displayName":"NEHEMIAS NICOLÁS RIVERA","userId":"15262051941950258843"},"user_tz":180},"id":"Y_CWhEH1WF3i"},"outputs":[],"source":["import numpy as np\n","from random import random"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1726529211219,"user":{"displayName":"NEHEMIAS NICOLÁS RIVERA","userId":"15262051941950258843"},"user_tz":180},"id":"0vgVoQQ-WKmG"},"outputs":[],"source":["# save activations and derivatives\n","# implement backpropagation\n","# implement gradient decent\n","# implement train\n","# train our net woth some dummy dataset\n","# make some prediction\n","\n","class MLP:\n","\n","  def __init__(self, num_inputs=3, num_hidden=[3, 3], num_outputs=2):\n","    \"\"\"\n","    MLP constructor\n","    Args:\n","      num_inputs (int): numero de entradas\n","      num_hidden (list): numero de neuronas ocultas\n","      num_outputs (int): numero de salidas\n","    \"\"\"\n","    self.num_inputs = num_inputs\n","    self.num_hidden = num_hidden\n","    self.num_outputs = num_outputs\n","\n","    # crear representacion generica de las capas\n","    layers = [num_inputs] + num_hidden + [num_outputs]\n","\n","    weights = []\n","    for i in range(len(layers) - 1):\n","      w = np.random.rand(layers[i], layers[i + 1])\n","      weights.append(w)\n","    self.weights = weights\n","\n","    derivatives = []\n","    for i in range(len(layers)-1):  #Si tenemos tres capas tenemos dos matrices W\n","      a = np.zeros((layers[i], layers[i+1]))\n","      derivatives.append(a)\n","    self.derivatives = derivatives\n","\n","    # crear representacion de las activaciones de las capas\n","    activations = []\n","    for i in range(len(layers)):\n","      a = np.zeros(layers[i])\n","      activations.append(a)\n","    self.activations = activations\n","\n","  def forward_propagate(self, inputs):\n","    \"\"\"\n","    Calcula la propagacion forward a traves de la red basado en las entradas\n","    Args:\n","      inputs (ndarray): entradas a la red\n","    Returns:\n","      activations (ndarray): salidas de la red\n","    \"\"\"\n","    activations = inputs\n","\n","    # la activacion de la primera capa\n","    self.activations[0] = activations\n","\n","    # itera a traves de las capa de la red\n","    for i, w in enumerate(self.weights):\n","      # Calcula las entradas netas\n","      net_inputs = np.dot(activations, w)\n","\n","      # Calcula la activacion\n","      activations = self._sigmoid(net_inputs)\n","      self.activations[i+1]= activations #guardamos la activacion\n","\n","    # a_3 = s(h_3)\n","    # h_3 = a_2 * W_2 ---> i = 2\n","\n","    return activations\n","\n","  def back_propagate(self,error, verbose=False):\n","    \"\"\"Backpropogates an error signal.\n","    Args:\n","        error (ndarray): The error to backprop.\n","    Returns:\n","        error (ndarray): The final error of the input\n","    \"\"\"\n","\n","    #Este metodo de backpropagation funciona para infita cantidad de capas\n","\n","    # dE/dW_i = (y - a_[i+1]) * s'(h_[i+1]) * a_i ---> error * s' * ai\n","    # s'(h_[i+1]) = s(h_[i+1]) * (1 - s(h_[i+1]))\n","    # s(h_[i+1]) = a_[i+1]\n","\n","    # dE/dw_[i-1] = (y - a_[i+1]) * s'(h_[i+1]) * W_i * s'(h_i) * a_[i-1]\n","\n","    # recorremos desde la ultima capa hasta la primera (al reves)\n","    for i in reversed(range(len(self.derivatives))):\n","      activations  = self.activations [i+1]\n","\n","      delta = error * self._sigmoid_derivative(activations ) #ndarray([0.1, 0.2]) --> ndarray([[0.1, 0.2]])\n","      delta_reshaped = delta.reshape(delta.shape[0], -1).T\n","\n","      current_activations = self.activations[i] #ndarray([0.1, 0.2]) --> ndarray([0.1], [0.2])\n","      current_activations_reshape = current_activations.reshape(current_activations.shape[0],-1)\n","\n","      self.derivatives[i] = np.dot(current_activations_reshape, delta_reshaped)\n","\n","      error = np.dot(delta, self.weights[i].T)  #calcular el error de la capa anterior ((y - a_[i+1]) * s'(h_[i+1]) * W_i)\n","\n","      if verbose:\n","        print(\"Derivatives for W{}: {}\".format(i,self.derivatives[i]))\n","\n","    return error\n","\n","  def train(self, inputs, targets, epochs, learning_rate):\n","\n","    for i in range(epochs):\n","      sum_error = 0\n","      for (input,target) in zip(inputs,targets):\n","        # forward propagation\n","        output = self.forward_propagate(input)\n","        # calcula error\n","        error = target - output\n","        # backpropagation\n","        self.back_propagate(error)\n","        # actualiza pesos (gradiente decendiente)\n","        self.gradient_descent(learning_rate)\n","        #report error para esta epoca (se acumula)\n","        sum_error += self._mse(target, output)\n","\n","      print(\"Error: {} at epoch {}\".format(sum_error/len(inputs), i))\n","\n","  def gradient_descent(self, learning_rate):\n","    for i in range(len(self.weights)):\n","      weights = self.weights[i]\n","      derivatives = self.derivatives[i]\n","      weights += derivatives * learning_rate\n","\n","  def _sigmoid_derivative(self,x):\n","    \"\"\"\n","    Calcula la derivada de la funcion sigmoid\n","    Args:\n","      x (float): value to be processed\n","    Returns:\n","      y (float): output\n","    \"\"\"\n","    return x * (1.0 - x)\n","\n","  def _mse(self, target, output):\n","    \"\"\"\n","    Calcula el error cuadratico medio\n","    Args:\n","      target (ndarray): el target de la red\n","      output (ndarray): la salida de la red\n","    Returns:\n","      error\n","    \"\"\"\n","    return np.average((target - output) ** 2)\n","\n","  def _sigmoid(self, x):\n","    \"\"\"\n","    Sigmoid activation function\n","    Args:\n","      x (float): value to be processed\n","    Returns:\n","      y (float): output\n","    \"\"\"\n","    return 1 / (1 + np.exp(-x))\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9057,"status":"ok","timestamp":1726529610996,"user":{"displayName":"NEHEMIAS NICOLÁS RIVERA","userId":"15262051941950258843"},"user_tz":180},"id":"5YckebmtWLRZ","outputId":"b4346e9a-c382-4261-8e68-8da224b938ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error: 0.05135555580048033 at epoch 0\n","Error: 0.043160012993711076 at epoch 1\n","Error: 0.04266075485817514 at epoch 2\n","Error: 0.04210160234753985 at epoch 3\n","Error: 0.041430434979587136 at epoch 4\n","Error: 0.04059090005366104 at epoch 5\n","Error: 0.039521368230955825 at epoch 6\n","Error: 0.0381566242338574 at epoch 7\n","Error: 0.036433688506280267 at epoch 8\n","Error: 0.034303144992154366 at epoch 9\n","Error: 0.031746032819444665 at epoch 10\n","Error: 0.028792923366939612 at epoch 11\n","Error: 0.02553685783837644 at epoch 12\n","Error: 0.02212925847960439 at epoch 13\n","Error: 0.01875341734192042 at epoch 14\n","Error: 0.01558361706010973 at epoch 15\n","Error: 0.012748613011890416 at epoch 16\n","Error: 0.010315038743583053 at epoch 17\n","Error: 0.00829253463537505 at epoch 18\n","Error: 0.00665128935930931 at epoch 19\n","Error: 0.0053411858760450005 at epoch 20\n","Error: 0.004306372062098373 at epoch 21\n","Error: 0.0034939339327578474 at epoch 22\n","Error: 0.0028578817329163444 at epoch 23\n","Error: 0.002360212877567551 at epoch 24\n","Error: 0.001970468810412981 at epoch 25\n","Error: 0.0016646803853922938 at epoch 26\n","Error: 0.0014241826457457713 at epoch 27\n","Error: 0.0012345198917373462 at epoch 28\n","Error: 0.0010845199238779326 at epoch 29\n","Error: 0.0009655474898157041 at epoch 30\n","Error: 0.000870918215563197 at epoch 31\n","Error: 0.0007954455437324078 at epoch 32\n","Error: 0.0007350934207887199 at epoch 33\n","Error: 0.0006867111033356504 at epoch 34\n","Error: 0.0006478308858385453 at epoch 35\n","Error: 0.0006165136955650545 at epoch 36\n","Error: 0.0005912309856498482 at epoch 37\n","Error: 0.0005707741365458354 at epoch 38\n","Error: 0.0005541847278065783 at epoch 39\n","Error: 0.0005407006796982526 at epoch 40\n","Error: 0.0005297144984551962 at epoch 41\n","Error: 0.0005207407847600962 at epoch 42\n","Error: 0.0005133908580606815 at epoch 43\n","Error: 0.0005073528682232534 at epoch 44\n","Error: 0.0005023761551361175 at epoch 45\n","Error: 0.0004982589094079715 at epoch 46\n","Error: 0.0004948384079283538 at epoch 47\n","Error: 0.000491983265045941 at epoch 48\n","Error: 0.0004895872670030358 at epoch 49\n","Error: 0.000487564454060524 at epoch 50\n","Error: 0.0004858451888915449 at epoch 51\n","Error: 0.0004843730068458147 at epoch 52\n","Error: 0.00048310208771851627 at epoch 53\n","Error: 0.0004819952227905356 at epoch 54\n","Error: 0.00048102217746609277 at epoch 55\n","Error: 0.0004801583705749212 at epoch 56\n","Error: 0.0004793838076601052 at epoch 57\n","Error: 0.0004786822183521405 at epoch 58\n","Error: 0.00047804035800910527 at epoch 59\n","Error: 0.00047744744177587455 at epoch 60\n","Error: 0.00047689468553986755 at epoch 61\n","Error: 0.0004763749332906306 at epoch 62\n","Error: 0.000475882354400622 at epoch 63\n","Error: 0.0004754121975486106 at epoch 64\n","Error: 0.00047496059057271613 at epoch 65\n","Error: 0.0004745243775984375 at epoch 66\n","Error: 0.00047410098644129825 at epoch 67\n","Error: 0.00047368832061550387 at epoch 68\n","Error: 0.000473284671353856 at epoch 69\n","Error: 0.000472888645911091 at epoch 70\n","Error: 0.00047249910912371866 at epoch 71\n","Error: 0.0004721151357667433 at epoch 72\n","Error: 0.00047173597170726525 at epoch 73\n","Error: 0.0004713610022277409 at epoch 74\n","Error: 0.0004709897261942829 at epoch 75\n","Error: 0.0004706217349911555 at epoch 76\n","Error: 0.00047025669534252765 at epoch 77\n","Error: 0.00046989433530501677 at epoch 78\n","Error: 0.0004695344328469452 at epoch 79\n","Error: 0.0004691768065379322 at epoch 80\n","Error: 0.0004688213079602534 at epoch 81\n","Error: 0.0004684678155249283 at epoch 82\n","Error: 0.00046811622943385215 at epoch 83\n","Error: 0.00046776646757684865 at epoch 84\n","Error: 0.00046741846219134313 at epoch 85\n","Error: 0.0004670721571440216 at epoch 86\n","Error: 0.0004667275057196956 at epoch 87\n","Error: 0.0004663844688236729 at epoch 88\n","Error: 0.00046604301352117574 at epoch 89\n","Error: 0.00046570311185140827 at epoch 90\n","Error: 0.0004653647398653395 at epoch 91\n","Error: 0.0004650278768456606 at epoch 92\n","Error: 0.00046469250467501294 at epoch 93\n","Error: 0.00046435860732485024 at epoch 94\n","Error: 0.0004640261704423811 at epoch 95\n","Error: 0.00046369518101722847 at epoch 96\n","Error: 0.0004633656271127974 at epoch 97\n","Error: 0.0004630374976501927 at epoch 98\n","Error: 0.0004627107822346939 at epoch 99\n","Error: 0.00046238547101674595 at epoch 100\n","Error: 0.00046206155458085405 at epoch 101\n","Error: 0.000461739023857034 at epoch 102\n","Error: 0.0004614178700504672 at epoch 103\n","Error: 0.0004610980845858391 at epoch 104\n","Error: 0.00046077965906345976 at epoch 105\n","Error: 0.00046046258522488583 at epoch 106\n","Error: 0.00046014685492610895 at epoch 107\n","Error: 0.0004598324601168385 at epoch 108\n","Error: 0.00045951939282459206 at epoch 109\n","Error: 0.00045920764514264297 at epoch 110\n","Error: 0.00045889720922099285 at epoch 111\n","Error: 0.00045858807725973855 at epoch 112\n","Error: 0.00045828024150430785 at epoch 113\n","Error: 0.00045797369424215197 at epoch 114\n","Error: 0.0004576684278005586 at epoch 115\n","Error: 0.00045736443454532353 at epoch 116\n","Error: 0.0004570617068800651 at epoch 117\n","Error: 0.00045676023724602844 at epoch 118\n","Error: 0.0004564600181222275 at epoch 119\n","Error: 0.00045616104202583383 at epoch 120\n","Error: 0.00045586330151274325 at epoch 121\n","Error: 0.0004555667891782283 at epoch 122\n","Error: 0.00045527149765765444 at epoch 123\n","Error: 0.00045497741962722686 at epoch 124\n","Error: 0.00045468454780470536 at epoch 125\n","Error: 0.00045439287495011965 at epoch 126\n","Error: 0.00045410239386643194 at epoch 127\n","Error: 0.0004538130974001449 at epoch 128\n","Error: 0.00045352497844186953 at epoch 129\n","Error: 0.00045323802992682064 at epoch 130\n","Error: 0.0004529522448352606 at epoch 131\n","Error: 0.000452667616192882 at epoch 132\n","Error: 0.00045238413707113066 at epoch 133\n","Error: 0.0004521018005874696 at epoch 134\n","Error: 0.0004518205999055962 at epoch 135\n","Error: 0.0004515405282356047 at epoch 136\n","Error: 0.00045126157883410196 at epoch 137\n","Error: 0.00045098374500427714 at epoch 138\n","Error: 0.00045070702009593154 at epoch 139\n","Error: 0.00045043139750547813 at epoch 140\n","Error: 0.00045015687067588415 at epoch 141\n","Error: 0.00044988343309661596 at epoch 142\n","Error: 0.00044961107830352435 at epoch 143\n","Error: 0.00044933979987871664 at epoch 144\n","Error: 0.00044906959145040777 at epoch 145\n","Error: 0.0004488004466927455 at epoch 146\n","Error: 0.00044853235932561475 at epoch 147\n","Error: 0.0004482653231144294 at epoch 148\n","Error: 0.0004479993318699096 at epoch 149\n","\n","\n","Our network believes that 0.3 + 0.1 is equal to 0.3947733938430912\n"]}],"source":["if __name__ == \"__main__\":\n","\n","  # create a dataset to train a network for the sum operation\n","  inputs = np.array([[random()/2 for _ in range(2)] for _ in range(1000)]) # array([[0.1, 0.2], [0.3,0.4]])\n","  targets = np.array([[i[0] + i[1]] for i in inputs]) # array([[0.3], [0.7]])\n","\n","  # crear un MLP\n","  mlp = MLP(2,[5],1)\n","\n","  # entrenar el MLP\n","  mlp.train(inputs, targets, 150, 0.1)\n","\n","    # crear data dummy\n","  input = np.array([0.3, 0.1])\n","  target = np.array([0.4])\n","\n","  # hacer una prediccion\n","  output = mlp.forward_propagate(input)\n","  print()\n","  print()\n","  print(\"Our network believes that {} + {} is equal to {}\".format(input[0], input[1], output[0]))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMDVaz4FK2iK4oaVBa1TN/e","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":0}
